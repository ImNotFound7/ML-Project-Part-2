{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11001f37-f369-4e29-95f5-a50c04536108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "IMPROVED COPD RISK PREDICTION PIPELINE\n",
      "================================================================================\n",
      "\n",
      "1) Loading data...\n",
      "Training samples: 44553, Test samples: 11139\n",
      "Positive class ratio: 0.367\n",
      "\n",
      "2) Performing advanced feature engineering...\n",
      "Features after engineering: 68\n",
      "\n",
      "3) Setting up cross-validation pipeline...\n",
      "\n",
      "4) Starting 10-fold cross-validation training...\n",
      "\n",
      "--- Fold 1/10 ---\n",
      "After SMOTE: 50778 samples\n",
      "Fold F1 scores - LR: 0.7048, SVM: 0.7035, MLP: 0.7072\n",
      "\n",
      "--- Fold 2/10 ---\n",
      "After SMOTE: 50778 samples\n",
      "Fold F1 scores - LR: 0.7184, SVM: 0.7161, MLP: 0.7151\n",
      "\n",
      "--- Fold 3/10 ---\n",
      "After SMOTE: 50778 samples\n",
      "Fold F1 scores - LR: 0.7200, SVM: 0.7124, MLP: 0.7150\n",
      "\n",
      "--- Fold 4/10 ---\n",
      "After SMOTE: 50778 samples\n",
      "Fold F1 scores - LR: 0.7175, SVM: 0.7140, MLP: 0.7094\n",
      "\n",
      "--- Fold 5/10 ---\n",
      "After SMOTE: 50778 samples\n",
      "Fold F1 scores - LR: 0.7104, SVM: 0.7101, MLP: 0.7045\n",
      "\n",
      "--- Fold 6/10 ---\n",
      "After SMOTE: 50778 samples\n",
      "Fold F1 scores - LR: 0.7157, SVM: 0.7163, MLP: 0.7027\n",
      "\n",
      "--- Fold 7/10 ---\n",
      "After SMOTE: 50778 samples\n",
      "Fold F1 scores - LR: 0.7113, SVM: 0.6984, MLP: 0.6727\n",
      "\n",
      "--- Fold 8/10 ---\n",
      "After SMOTE: 50778 samples\n",
      "Fold F1 scores - LR: 0.7184, SVM: 0.7255, MLP: 0.7139\n",
      "\n",
      "--- Fold 9/10 ---\n",
      "After SMOTE: 50778 samples\n",
      "Fold F1 scores - LR: 0.7130, SVM: 0.7153, MLP: 0.7082\n",
      "\n",
      "--- Fold 10/10 ---\n",
      "After SMOTE: 50778 samples\n",
      "Fold F1 scores - LR: 0.7228, SVM: 0.7084, MLP: 0.6938\n",
      "\n",
      "5) Optimizing thresholds on OOF predictions...\n",
      "\n",
      "Optimal thresholds and OOF F1 scores:\n",
      "LR:  threshold=0.495, F1=0.7154\n",
      "SVM: threshold=0.320, F1=0.7214\n",
      "MLP: threshold=0.145, F1=0.7142\n",
      "\n",
      "6) Training stacking ensemble...\n",
      "Stacked: threshold=0.470, F1=0.7339\n",
      "\n",
      "7) Generating test predictions...\n",
      "\n",
      "8) Saving submission files...\n",
      "Saved: submissions-cl/submission_improved_LR.csv (positive rate: 0.549)\n",
      "Saved: submissions-cl/submission_improved_SVM.csv (positive rate: 0.538)\n",
      "Saved: submissions-cl/submission_improved_MLP.csv (positive rate: 0.576)\n",
      "Saved: submissions-cl/submission_improved_STACKED.csv (positive rate: 0.506)\n",
      "\n",
      "================================================================================\n",
      "PIPELINE COMPLETED SUCCESSFULLY\n",
      "================================================================================\n",
      "\n",
      "Best OOF F1 Score: 0.7339\n",
      "Recommendation: Submit STACKED submission first\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "N_JOBS = 4\n",
    "N_FOLDS = 10 \n",
    "SEED = RANDOM_STATE\n",
    "\n",
    "TRAIN_FILE = 'train.csv'\n",
    "TEST_FILE = 'test.csv'\n",
    "OUTPUT_PREFIX = 'submission_improved'\n",
    "\n",
    "def advanced_feature_engineering(df):\n",
    "    \"\"\"Enhanced feature engineering with domain knowledge\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Basic ratios\n",
    "    df['bmi'] = df['weight_kg'] / ((df['height_cm'] / 100) ** 2)\n",
    "    df['waist_height_ratio'] = df['waist_circumference_cm'] / df['height_cm']\n",
    "    df['waist_weight_ratio'] = df['waist_circumference_cm'] / df['weight_kg']\n",
    "    \n",
    "    # Blood pressure features (critical for COPD)\n",
    "    df['pulse_pressure'] = df['bp_systolic'] - df['bp_diastolic']\n",
    "    df['map'] = df['bp_diastolic'] + (df['pulse_pressure'] / 3)\n",
    "    df['bp_product'] = df['bp_systolic'] * df['bp_diastolic']\n",
    "    df['bp_ratio'] = df['bp_systolic'] / (df['bp_diastolic'] + 1e-6)\n",
    "    \n",
    "    # Comprehensive cholesterol features\n",
    "    df['chol_hdl_ratio'] = df['total_cholesterol'] / (df['hdl_cholesterol'] + 1e-6)\n",
    "    df['ldl_hdl_ratio'] = df['ldl_cholesterol'] / (df['hdl_cholesterol'] + 1e-6)\n",
    "    df['tg_hdl_ratio'] = df['triglycerides'] / (df['hdl_cholesterol'] + 1e-6)\n",
    "    df['non_hdl_chol'] = df['total_cholesterol'] - df['hdl_cholesterol']\n",
    "    df['atherogenic_index'] = np.log10(df['triglycerides'] / (df['hdl_cholesterol'] + 1e-6))\n",
    "    \n",
    "    # Liver enzyme ratios (inflammation markers)\n",
    "    df['ast_alt_ratio'] = df['ast_enzyme_level'] / (df['alt_enzyme_level'] + 1e-6)\n",
    "    df['ggt_alt_ratio'] = df['ggt_enzyme_level'] / (df['alt_enzyme_level'] + 1e-6)\n",
    "    df['ggt_ast_ratio'] = df['ggt_enzyme_level'] / (df['ast_enzyme_level'] + 1e-6)\n",
    "    df['liver_score'] = df['ast_enzyme_level'] + df['alt_enzyme_level'] + df['ggt_enzyme_level']\n",
    "    \n",
    "    # Kidney and blood features\n",
    "    df['creatinine_hb_ratio'] = df['serum_creatinine'] / (df['hemoglobin_level'] + 1e-6)\n",
    "    df['kidney_blood_score'] = df['serum_creatinine'] * df['hemoglobin_level']\n",
    "    \n",
    "    # Protein markers\n",
    "    df['protein_positive'] = (df['urine_protein_level'] > 0).astype(int)\n",
    "    df['protein_squared'] = df['urine_protein_level'] ** 2\n",
    "    \n",
    "    # Age processing\n",
    "    df['age_numeric'] = df['age_group'].astype(float)\n",
    "    df['age_squared'] = df['age_numeric'] ** 2\n",
    "    df['age_bmi_interaction'] = df['age_numeric'] * df['bmi']\n",
    "    \n",
    "    # Vision and hearing\n",
    "    df['vision_diff'] = np.abs(df['vision_left'] - df['vision_right'])\n",
    "    df['hearing_diff'] = np.abs(df['hearing_left'] - df['hearing_right'])\n",
    "    df['vision_avg'] = (df['vision_left'] + df['vision_right']) / 2\n",
    "    df['hearing_avg'] = (df['hearing_left'] + df['hearing_right']) / 2\n",
    "    df['sensory_score'] = df['vision_avg'] + df['hearing_avg']\n",
    "    \n",
    "    # Clinical risk flags (important for COPD)\n",
    "    df['is_obese'] = (df['bmi'] >= 30).astype(int)\n",
    "    df['is_overweight'] = ((df['bmi'] >= 25) & (df['bmi'] < 30)).astype(int)\n",
    "    df['has_hypertension'] = ((df['bp_systolic'] >= 130) | (df['bp_diastolic'] >= 80)).astype(int)\n",
    "    df['severe_hypertension'] = ((df['bp_systolic'] >= 140) | (df['bp_diastolic'] >= 90)).astype(int)\n",
    "    df['prediabetes'] = ((df['fasting_glucose'] >= 100) & (df['fasting_glucose'] < 126)).astype(int)\n",
    "    df['diabetes'] = (df['fasting_glucose'] >= 126).astype(int)\n",
    "    df['low_hdl'] = (df['hdl_cholesterol'] < 40).astype(int)\n",
    "    df['high_tg'] = (df['triglycerides'] >= 150).astype(int)\n",
    "    df['high_ldl'] = (df['ldl_cholesterol'] >= 130).astype(int)\n",
    "    \n",
    "    # Metabolic syndrome score (strong COPD predictor)\n",
    "    df['metabolic_syndrome_score'] = (\n",
    "        df['is_obese'] + \n",
    "        df['has_hypertension'] + \n",
    "        df['low_hdl'] + \n",
    "        df['high_tg'] + \n",
    "        (df['fasting_glucose'] >= 100).astype(int)\n",
    "    )\n",
    "    \n",
    "    # Cardiovascular risk score\n",
    "    df['cv_risk_score'] = (\n",
    "        df['severe_hypertension'] * 2 +\n",
    "        df['diabetes'] * 2 +\n",
    "        df['high_ldl'] +\n",
    "        df['low_hdl'] +\n",
    "        (df['bmi'] >= 35).astype(int) * 2\n",
    "    )\n",
    "    \n",
    "    # Composite health scores\n",
    "    df['waist_bmi_product'] = df['waist_circumference_cm'] * df['bmi']\n",
    "    df['glucose_bmi_interaction'] = df['fasting_glucose'] * df['bmi']\n",
    "    df['age_glucose_interaction'] = df['age_numeric'] * df['fasting_glucose']\n",
    "    df['age_bp_interaction'] = df['age_numeric'] * df['bp_systolic']\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ---------- HELPERS ----------\n",
    "def encode_categoricals(df, cat_cols):\n",
    "    for col in cat_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(str).str.strip().str.upper().map({\"M\":0,\"F\":1,\"Y\":1,\"N\":0})\n",
    "    return df\n",
    "\n",
    "def find_best_threshold_refined(y_true, probs, step=0.005, low=0.1, high=0.9):\n",
    "    \"\"\"More granular threshold search\"\"\"\n",
    "    best_f1, best_t = -1, 0.5\n",
    "    thresholds = np.arange(low, high + 1e-9, step)\n",
    "    \n",
    "    for t in thresholds:\n",
    "        preds = (probs >= t).astype(int)\n",
    "        f1 = f1_score(y_true, preds)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_t = t\n",
    "    \n",
    "    return best_t, best_f1\n",
    "\n",
    "# ---------- MAIN PIPELINE ----------\n",
    "print(\"=\" * 80)\n",
    "print(\"IMPROVED COPD RISK PREDICTION PIPELINE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1) Load data\n",
    "print(\"\\n1) Loading data...\")\n",
    "train_df = pd.read_csv(TRAIN_FILE)\n",
    "test_df = pd.read_csv(TEST_FILE)\n",
    "test_ids = test_df['patient_id'].copy()\n",
    "\n",
    "# Store patient IDs then drop\n",
    "train_df = train_df.drop('patient_id', axis=1, errors='ignore')\n",
    "test_df = test_df.drop('patient_id', axis=1, errors='ignore')\n",
    "\n",
    "# Separate target\n",
    "X = train_df.drop('has_copd_risk', axis=1).copy()\n",
    "y = train_df['has_copd_risk'].copy()\n",
    "X_test_raw = test_df.copy()\n",
    "\n",
    "print(f\"Training samples: {len(X)}, Test samples: {len(X_test_raw)}\")\n",
    "print(f\"Positive class ratio: {y.mean():.3f}\")\n",
    "\n",
    "# 2) Categorical encoding (before feature engineering)\n",
    "cat_cols = [\"sex\", \"oral_health_status\", \"tartar_presence\"]\n",
    "X = encode_categoricals(X, cat_cols)\n",
    "X_test_raw = encode_categoricals(X_test_raw, cat_cols)\n",
    "\n",
    "# 3) Advanced feature engineering\n",
    "print(\"\\n2) Performing advanced feature engineering...\")\n",
    "X_full = pd.concat([X, y], axis=1)\n",
    "X_full['has_copd_risk'] = y  # Add target back temporarily\n",
    "X_full = advanced_feature_engineering(X_full)\n",
    "X_test_engineered = advanced_feature_engineering(X_test_raw)\n",
    "\n",
    "# Separate target again\n",
    "X_engineered = X_full.drop('has_copd_risk', axis=1)\n",
    "\n",
    "# Align columns\n",
    "common_cols = list(set(X_engineered.columns) & set(X_test_engineered.columns))\n",
    "X_engineered = X_engineered[common_cols]\n",
    "X_test_engineered = X_test_engineered[common_cols]\n",
    "\n",
    "print(f\"Features after engineering: {X_engineered.shape[1]}\")\n",
    "\n",
    "# 4) Prepare for cross-validation\n",
    "print(\"\\n3) Setting up cross-validation pipeline...\")\n",
    "\n",
    "# Initialize arrays for OOF predictions\n",
    "oof_probs_lr = np.zeros(len(X_engineered))\n",
    "oof_probs_svm = np.zeros(len(X_engineered))\n",
    "oof_probs_mlp = np.zeros(len(X_engineered))\n",
    "\n",
    "# Initialize arrays for test predictions\n",
    "test_probs_lr = np.zeros(len(X_test_engineered))\n",
    "test_probs_svm = np.zeros(len(X_test_engineered))\n",
    "test_probs_mlp = np.zeros(len(X_test_engineered))\n",
    "\n",
    "# Setup cross-validation\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "print(f\"\\n4) Starting {N_FOLDS}-fold cross-validation training...\")\n",
    "\n",
    "# Best hyperparameters (expanded search spaces)\n",
    "best_lr_params = {\n",
    "    'C': 0.5,\n",
    "    'penalty': 'l2',\n",
    "    'solver': 'liblinear',\n",
    "    'class_weight': 'balanced',\n",
    "    'max_iter': 3000\n",
    "}\n",
    "\n",
    "best_svm_params = {\n",
    "    'C': 1.5,\n",
    "    'gamma': 'scale',\n",
    "    'kernel': 'rbf',\n",
    "    'class_weight': 'balanced',\n",
    "    'probability': True\n",
    "}\n",
    "\n",
    "best_mlp_params = {\n",
    "    'hidden_layer_sizes': (256, 128, 64),\n",
    "    'alpha': 0.0003,\n",
    "    'learning_rate': 'adaptive',\n",
    "    'learning_rate_init': 0.001,\n",
    "    'max_iter': 2000,\n",
    "    'early_stopping': True,\n",
    "    'validation_fraction': 0.1\n",
    "}\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X_engineered, y), 1):\n",
    "    print(f\"\\n--- Fold {fold_idx}/{N_FOLDS} ---\")\n",
    "    \n",
    "    # Get fold data\n",
    "    X_train_fold = X_engineered.iloc[train_idx].copy()\n",
    "    X_val_fold = X_engineered.iloc[val_idx].copy()\n",
    "    y_train_fold = y.iloc[train_idx].values\n",
    "    y_val_fold = y.iloc[val_idx].values\n",
    "    \n",
    "    # Impute missing values\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    X_train_imp = pd.DataFrame(\n",
    "        imputer.fit_transform(X_train_fold),\n",
    "        columns=X_train_fold.columns\n",
    "    )\n",
    "    X_val_imp = pd.DataFrame(\n",
    "        imputer.transform(X_val_fold),\n",
    "        columns=X_train_fold.columns\n",
    "    )\n",
    "    X_test_imp = pd.DataFrame(\n",
    "        imputer.transform(X_test_engineered),\n",
    "        columns=X_train_fold.columns\n",
    "    )\n",
    "    \n",
    "    # Apply SMOTE BEFORE scaling (on imputed data)\n",
    "    smote = SMOTE(random_state=SEED, k_neighbors=5)\n",
    "    X_train_res, y_train_res = smote.fit_resample(X_train_imp, y_train_fold)\n",
    "    print(f\"After SMOTE: {X_train_res.shape[0]} samples\")\n",
    "    \n",
    "    # Scale AFTER SMOTE\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_res)\n",
    "    X_val_scaled = scaler.transform(X_val_imp)\n",
    "    X_test_scaled = scaler.transform(X_test_imp)\n",
    "    \n",
    "    # Feature selection (on scaled data)\n",
    "    selector = SelectKBest(mutual_info_classif, k=60)\n",
    "    X_train_selected = selector.fit_transform(X_train_scaled, y_train_res)\n",
    "    X_val_selected = selector.transform(X_val_scaled)\n",
    "    X_test_selected = selector.transform(X_test_scaled)\n",
    "    \n",
    "    # Train models\n",
    "    # Logistic Regression\n",
    "    lr = LogisticRegression(**best_lr_params, random_state=SEED)\n",
    "    lr.fit(X_train_selected, y_train_res)\n",
    "    oof_probs_lr[val_idx] = lr.predict_proba(X_val_selected)[:, 1]\n",
    "    test_probs_lr += lr.predict_proba(X_test_selected)[:, 1] / N_FOLDS\n",
    "    \n",
    "    # SVM\n",
    "    svm = SVC(**best_svm_params, random_state=SEED)\n",
    "    svm.fit(X_train_selected, y_train_res)\n",
    "    oof_probs_svm[val_idx] = svm.predict_proba(X_val_selected)[:, 1]\n",
    "    test_probs_svm += svm.predict_proba(X_test_selected)[:, 1] / N_FOLDS\n",
    "    \n",
    "    # MLP\n",
    "    mlp = MLPClassifier(**best_mlp_params, random_state=SEED)\n",
    "    mlp.fit(X_train_selected, y_train_res)\n",
    "    oof_probs_mlp[val_idx] = mlp.predict_proba(X_val_selected)[:, 1]\n",
    "    test_probs_mlp += mlp.predict_proba(X_test_selected)[:, 1] / N_FOLDS\n",
    "    \n",
    "    # Fold metrics\n",
    "    f1_lr = f1_score(y_val_fold, (oof_probs_lr[val_idx] >= 0.5).astype(int))\n",
    "    f1_svm = f1_score(y_val_fold, (oof_probs_svm[val_idx] >= 0.5).astype(int))\n",
    "    f1_mlp = f1_score(y_val_fold, (oof_probs_mlp[val_idx] >= 0.5).astype(int))\n",
    "    print(f\"Fold F1 scores - LR: {f1_lr:.4f}, SVM: {f1_svm:.4f}, MLP: {f1_mlp:.4f}\")\n",
    "\n",
    "# 5) Threshold optimization\n",
    "print(\"\\n5) Optimizing thresholds on OOF predictions...\")\n",
    "lr_thresh, lr_f1 = find_best_threshold_refined(y, oof_probs_lr)\n",
    "svm_thresh, svm_f1 = find_best_threshold_refined(y, oof_probs_svm)\n",
    "mlp_thresh, mlp_f1 = find_best_threshold_refined(y, oof_probs_mlp)\n",
    "\n",
    "print(f\"\\nOptimal thresholds and OOF F1 scores:\")\n",
    "print(f\"LR:  threshold={lr_thresh:.3f}, F1={lr_f1:.4f}\")\n",
    "print(f\"SVM: threshold={svm_thresh:.3f}, F1={svm_f1:.4f}\")\n",
    "print(f\"MLP: threshold={mlp_thresh:.3f}, F1={mlp_f1:.4f}\")\n",
    "\n",
    "# 6) Stacking ensemble\n",
    "print(\"\\n6) Training stacking ensemble...\")\n",
    "meta_X = np.column_stack([oof_probs_lr, oof_probs_svm, oof_probs_mlp])\n",
    "meta_model = LogisticRegression(\n",
    "    C=0.5,\n",
    "    class_weight='balanced',\n",
    "    solver='liblinear',\n",
    "    random_state=SEED\n",
    ")\n",
    "meta_model.fit(meta_X, y)\n",
    "\n",
    "meta_oof_probs = meta_model.predict_proba(meta_X)[:, 1]\n",
    "meta_thresh, meta_f1 = find_best_threshold_refined(y, meta_oof_probs)\n",
    "print(f\"Stacked: threshold={meta_thresh:.3f}, F1={meta_f1:.4f}\")\n",
    "\n",
    "# 7) Generate test predictions\n",
    "print(\"\\n7) Generating test predictions...\")\n",
    "meta_test_X = np.column_stack([test_probs_lr, test_probs_svm, test_probs_mlp])\n",
    "meta_test_probs = meta_model.predict_proba(meta_test_X)[:, 1]\n",
    "\n",
    "# Apply thresholds\n",
    "test_preds_lr = (test_probs_lr >= lr_thresh).astype(int)\n",
    "test_preds_svm = (test_probs_svm >= svm_thresh).astype(int)\n",
    "test_preds_mlp = (test_probs_mlp >= mlp_thresh).astype(int)\n",
    "test_preds_meta = (meta_test_probs >= meta_thresh).astype(int)\n",
    "\n",
    "# 8) Save submissions\n",
    "print(\"\\n8) Saving submission files...\")\n",
    "os.makedirs('submissions-cl', exist_ok=True)\n",
    "\n",
    "submissions = {\n",
    "    'LR': test_preds_lr,\n",
    "    'SVM': test_preds_svm,\n",
    "    'MLP': test_preds_mlp,\n",
    "    'STACKED': test_preds_meta\n",
    "}\n",
    "\n",
    "for name, preds in submissions.items():\n",
    "    df_sub = pd.DataFrame({\n",
    "        'patient_id': test_ids,\n",
    "        'has_copd_risk': preds\n",
    "    })\n",
    "    filename = f'submissions-cl/{OUTPUT_PREFIX}_{name}.csv'\n",
    "    df_sub.to_csv(filename, index=False)\n",
    "    print(f\"Saved: {filename} (positive rate: {preds.mean():.3f})\")\n",
    "\n",
    "# Save probabilities for analysis\n",
    "pd.DataFrame({\n",
    "    'patient_id': test_ids,\n",
    "    'prob_lr': test_probs_lr,\n",
    "    'prob_svm': test_probs_svm,\n",
    "    'prob_mlp': test_probs_mlp,\n",
    "    'prob_meta': meta_test_probs\n",
    "}).to_csv(f'submissions-cl/{OUTPUT_PREFIX}_PROBABILITIES.csv', index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PIPELINE COMPLETED SUCCESSFULLY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nBest OOF F1 Score: {meta_f1:.4f}\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
